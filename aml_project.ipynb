{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/020 | Train: 60.57% | Validation: 27.21% | Time: 8.24 min\n",
      "Epoch: 002/020 | Train: 79.75% | Validation: 68.50% | Time: 16.54 min\n",
      "Epoch: 003/020 | Train: 68.87% | Validation: 41.54% | Time: 24.81 min\n",
      "Epoch: 004/020 | Train: 60.96% | Validation: 25.86% | Time: 33.16 min\n",
      "Epoch: 005/020 | Train: 66.86% | Validation: 99.88% | Time: 41.31 min\n",
      "Epoch: 006/020 | Train: 92.17% | Validation: 97.06% | Time: 49.94 min\n",
      "Epoch: 007/020 | Train: 94.23% | Validation: 93.87% | Time: 62.04 min\n",
      "Epoch: 008/020 | Train: 93.65% | Validation: 95.10% | Time: 70.58 min\n",
      "Epoch: 009/020 | Train: 94.34% | Validation: 97.06% | Time: 79.08 min\n",
      "Epoch: 010/020 | Train: 95.78% | Validation: 93.75% | Time: 87.52 min\n",
      "Early stopping after 10 epochs\n",
      "Total Training Time: 87.52 min\n",
      "Test accuracy 94.36%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# Constants\n",
    "IMGWIDTH = 224  # Smaller input image size\n",
    "RANDOM_SEED = 888\n",
    "BATCH_SIZE = 64  # Smaller batch size for faster training\n",
    "NUM_EPOCHS = 20\n",
    "SPLITRATIO = [0.80, 0.95, 0.1]\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Set seed for reproducibility\n",
    "os.environ[\"PL_GLOBAL_SEED\"] = str(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "# Data transformations\n",
    "img_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((IMGWIDTH, IMGWIDTH)),\n",
    "    torchvision.transforms.RandomHorizontalFlip(p=0.5),  # Data augmentation\n",
    "    torchvision.transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Data augmentation\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "dataset = torchvision.datasets.ImageFolder(root=\"D:\\\\Abhishek\\\\Spring 24\\\\AML\\\\Project\\\\Data\\\\Final/\", transform=img_transform)\n",
    "\n",
    "# Split dataset\n",
    "train_idxs = torch.arange(0, int(SPLITRATIO[0] * len(dataset)))\n",
    "test_idxs = torch.arange(int(SPLITRATIO[0] * len(dataset)), int(SPLITRATIO[1] * len(dataset)))\n",
    "valid_idxs = torch.arange(int(SPLITRATIO[1] * len(dataset)), len(dataset))\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=4,\n",
    "    sampler=torch.utils.data.SubsetRandomSampler(train_idxs),\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=4,\n",
    "    sampler=torch.utils.data.SubsetRandomSampler(test_idxs))\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=4,\n",
    "    sampler=torch.utils.data.SubsetRandomSampler(valid_idxs))\n",
    "\n",
    "# Use a smaller model architecture (e.g., ResNet-18)\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 2)  # Binary classification\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# Use mixed precision training\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)  # Reduce LR by 10x every 5 epochs\n",
    "\n",
    "start_time = time.time()\n",
    "train_acc_list, valid_acc_list = [], []\n",
    "\n",
    "def calc_accuracy(model, data_loader, device):\n",
    "    model.eval()\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for features, targets in data_loader:\n",
    "            features = features.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            logits = model(features)\n",
    "            _, predictions = torch.max(logits, 1)\n",
    "            \n",
    "            total_preds += targets.size(0)\n",
    "            correct_preds += (predictions == targets).sum().item()\n",
    "    \n",
    "    accuracy = (correct_preds / total_preds) * 100\n",
    "    return accuracy\n",
    "\n",
    "# Early stopping variables\n",
    "patience = 5  # Stop training after 5 epochs without validation improvement\n",
    "best_val_acc = 0.0\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "\n",
    "    for features, targets in train_loader:\n",
    "        features = features.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "\n",
    "        with torch.cuda.amp.autocast():  # Mixed precision training\n",
    "            logits = model(features)\n",
    "            loss = criterion(logits, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Gradient clipping\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "    scheduler.step()  # Update learning rate\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_acc = calc_accuracy(model, train_loader, device=DEVICE)\n",
    "        valid_acc = calc_accuracy(model, val_loader, device=DEVICE)\n",
    "        train_acc_list.append(train_acc)  # No need for .item()\n",
    "        valid_acc_list.append(valid_acc)  # No need for .item()\n",
    "\n",
    "    elapsed = (time.time() - start_time) / 60\n",
    "    print(f\"Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | Train: {train_acc :.2f}% | Validation: {valid_acc :.2f}% | Time: {elapsed:.2f} min\")\n",
    "\n",
    "    # Early stopping\n",
    "    if valid_acc > best_val_acc:\n",
    "        best_val_acc = valid_acc\n",
    "        epochs_without_improvement = 0\n",
    "        torch.save(model.state_dict(), 'best_model.pth')  # Save the best model\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"Early stopping after {epoch+1} epochs\")\n",
    "            break\n",
    "\n",
    "elapsed = (time.time() - start_time) / 60\n",
    "print(f\"Total Training Time: {elapsed:.2f} min\")\n",
    "\n",
    "test_acc = calc_accuracy(model, test_loader, device=DEVICE)\n",
    "print(f\"Test accuracy {test_acc :.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
